{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from docx import Document\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "\n",
    "xls_path = '../data/raw/desafioaluno.xlsx'\n",
    "doc_path = '../data/raw/contexto_aluno.docx'\n",
    "prompt_path = '../data/raw/system_prompt.docx'\n",
    "\n",
    "client = OpenAI (\n",
    "api_key = os.getenv('OPEN_API_KEY')\n",
    ")\n",
    "\n",
    "\n",
    "xls = pd.read_excel(xls_path)\n",
    "doc = Document(doc_path)\n",
    "prompt = Document(prompt_path)\n",
    "\n",
    "doc_text ='\\n'.join([paragraph.text for paragraph in doc.paragraphs])\n",
    "prompt_text = '\\n'.join([paragraph.text for paragraph in prompt.paragraphs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.2 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ler_docx(file_path):\n",
    "    \"\"\"L√™ um arquivo .docx e retorna seu conte√∫do como string\"\"\"\n",
    "    doc = Document(file_path)\n",
    "    texto = \"\\n\".join([paragrafo.text for paragrafo in doc.paragraphs])\n",
    "    return texto\n",
    "\n",
    "\n",
    "def get_completion(xls_file_path, doc_text, prompt_text, model=\"gpt-4o-mini\"):\n",
    "\n",
    "    xls_data = pd.read_excel(xls_file_path)\n",
    "    xls_text = xls_data.to_string(index=False)\n",
    "\n",
    "    \n",
    "\n",
    "    # Criando mensagens\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": prompt_text},\n",
    "        {\"role\": \"user\", \"content\": f\"Aqui est√£o os dois arquivos:\\n\\nüìÑ **Arquivo Excel:**\\n{xls_text}\\n\\nüìÑ **Arquivo Texto:**\\n{doc_text}\\n\\n\"}\n",
    "    ]\n",
    "\n",
    "    #Fazendo a requisi√ß√£o para OpenAI\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        temperature=0.1\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "    #return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Feedback Detalhado sobre o Projeto de An√°lise de Dados\n",
      "\n",
      "#### 1. Compreens√£o do Desafio\n",
      "O aluno abordou o desafio de forma adequada, focando nas tr√™s √°reas principais: reten√ß√£o de clientes, segmenta√ß√£o de clientes e desempenho de produtos e localiza√ß√µes. O relat√≥rio apresenta uma an√°lise coerente e insights relevantes, alinhando-se aos objetivos estabelecidos no desafio.\n",
      "\n",
      "#### 2. Avalia√ß√£o T√©cnica\n",
      "- **Precis√£o dos C√°lculos e Gr√°ficos**: A an√°lise de cohort foi bem executada, com a apresenta√ß√£o de um heatmap que ilustra a reten√ß√£o de clientes. No entanto, seria interessante incluir uma an√°lise mais detalhada sobre os fatores que influenciam a reten√ß√£o, como sazonalidade e campanhas espec√≠ficas.\n",
      "- **Segmenta√ß√£o RFM**: A segmenta√ß√£o foi realizada corretamente, mas faltaram gr√°ficos que ilustrassem a distribui√ß√£o dos segmentos de clientes. A inclus√£o de gr√°ficos de barras ou pizza poderia facilitar a visualiza√ß√£o dos dados.\n",
      "- **Desempenho de Produtos e Localiza√ß√µes**: A an√°lise dos produtos mais e menos vendidos foi apresentada, mas faltou um ranking claro das lojas com melhor desempenho. Sugiro a inclus√£o de uma tabela ou gr√°fico que mostre essa informa√ß√£o de forma mais clara.\n",
      "\n",
      "#### 3. Avalia√ß√£o do Relat√≥rio\n",
      "- **Estrutura**: O relat√≥rio est√° bem estruturado, com uma introdu√ß√£o clara, desenvolvimento coerente e conclus√£o que resume os principais insights.\n",
      "- **Justificativas**: As justificativas para as an√°lises realizadas s√£o adequadas, mas poderiam ser mais detalhadas em algumas se√ß√µes, especialmente na parte de segmenta√ß√£o RFM e desempenho de produtos.\n",
      "- **Insights**: Os insights apresentados fazem sentido e est√£o bem alinhados com os dados. No entanto, a recomenda√ß√£o de a√ß√µes poderia ser mais espec√≠fica em rela√ß√£o a como implementar as estrat√©gias sugeridas.\n",
      "\n",
      "#### 4. Feedback e Pontua√ß√£o\n",
      "**Pontos Positivos**:\n",
      "- A an√°lise de cohort foi bem executada e apresentou um heatmap claro.\n",
      "- A segmenta√ß√£o RFM identificou corretamente os grupos de clientes e suas caracter√≠sticas.\n",
      "- O relat√≥rio est√° bem estruturado e apresenta insights relevantes.\n",
      "\n",
      "**Oportunidades de Melhoria**:\n",
      "- Incluir gr√°ficos que ilustrem a distribui√ß√£o dos segmentos de clientes e o desempenho das lojas.\n",
      "- Detalhar mais as justificativas para as an√°lises e recomenda√ß√µes.\n",
      "- Considerar a inclus√£o de uma an√°lise mais profunda sobre os fatores\n"
     ]
    }
   ],
   "source": [
    "resultado = get_completion(xls_path, doc_text, prompt_text)\n",
    "print(resultado)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
